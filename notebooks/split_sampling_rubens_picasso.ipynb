{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08732223",
   "metadata": {},
   "source": [
    "# Split & Sampling Notebook â€” Rubens vs Picasso\n",
    "\n",
    "Deze notebook maakt **train/val/test** datasets aan voor het 2-klassen experiment **Rubens vs Picasso**, met drie varianten:\n",
    "- **imbalanced** (originele verdeling)\n",
    "- **undersampled** (beide klassen even groot = kleinste klasse)\n",
    "- **oversampled** (train-set gebalanceerd door duplicatie)\n",
    "\n",
    "ðŸ“Œ **Input (brondata):** `schilderijen/` (hier zitten je opgeschoonde JPG+RGB afbeeldingen)\n",
    "\n",
    "ðŸ“Œ **Output (trainbare datasets):** `datasets/rubens_picasso/<variant>/{train,val,test}/<klasse>/...`\n",
    "\n",
    "âš ï¸ Belangrijk: de **testset** blijft altijd gebaseerd op unieke originele afbeeldingen (geen duplicaten), zodat evaluatie eerlijk blijft.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c7d97",
   "metadata": {},
   "source": [
    "## 0. Imports & configuratie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# ====== PAS AAN ALS JE PADEN ANDERS HETEN ======\n",
    "SRC_ROOT = Path(\"schilderijen\")            # bron: opgeschoonde data\n",
    "OUT_ROOT = Path(\"datasets/rubens_picasso\") # output: train/val/test folders\n",
    "\n",
    "CLASSES = [\"Rubens\", \"Picasso\"]\n",
    "\n",
    "# Hold-out split (train/val/test)\n",
    "SPLIT = {\"train\": 0.70, \"val\": 0.15, \"test\": 0.15}\n",
    "\n",
    "# Reproduceerbaarheid\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# Veiligheid: als True -> bestaande outputmap verwijderen en opnieuw maken\n",
    "OVERWRITE = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dee6a",
   "metadata": {},
   "source": [
    "## 1. Snelle checks\n",
    "We controleren of de bronmappen bestaan en hoeveel afbeeldingen er per klasse aanwezig zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3deab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(class_name: str):\n",
    "    \"\"\"Geef alle JPG bestanden terug voor een klasse.\"\"\"\n",
    "    class_dir = SRC_ROOT / class_name\n",
    "    return sorted([p for p in class_dir.glob(\"*.jpg\") if p.is_file()])\n",
    "\n",
    "# Check bronmappen\n",
    "for c in CLASSES:\n",
    "    assert (SRC_ROOT / c).exists(), f\"Bronmap ontbreekt: {SRC_ROOT / c}\"\n",
    "\n",
    "files_by_class = {c: list_images(c) for c in CLASSES}\n",
    "counts = {c: len(files_by_class[c]) for c in CLASSES}\n",
    "\n",
    "print(\"Aantal afbeeldingen per klasse (brondata):\")\n",
    "for c in CLASSES:\n",
    "    print(f\" - {c}: {counts[c]}\")\n",
    "\n",
    "min_n = min(counts.values())\n",
    "max_n = max(counts.values())\n",
    "\n",
    "print(f\"\\nmin_n (kleinste klasse) = {min_n}\")\n",
    "print(f\"max_n (grootste klasse)  = {max_n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a767c86",
   "metadata": {},
   "source": [
    "## 2. Hulpfuncties\n",
    "We maken functies om:\n",
    "- mappen te (her)maken\n",
    "- een hold-out split uit te voeren\n",
    "- bestanden te kopiÃ«ren (met unieke naam indien duplicaten nodig zijn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_output_folder(path: Path, overwrite: bool = False):\n",
    "    \"\"\"Maak output folder leeg (optioneel) en zet basisstructuur klaar.\"\"\"\n",
    "    if path.exists() and overwrite:\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ensure_split_dirs(base: Path, classes=CLASSES):\n",
    "    \"\"\"Maak train/val/test + class subfolders aan.\"\"\"\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for c in classes:\n",
    "            (base / split / c).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def holdout_split(file_list, split=SPLIT):\n",
    "    \"\"\"Shuffle en split Ã©Ã©n lijst in train/val/test.\"\"\"\n",
    "    file_list = file_list.copy()\n",
    "    random.shuffle(file_list)\n",
    "    n = len(file_list)\n",
    "    n_train = int(n * split[\"train\"])\n",
    "    n_val   = int(n * split[\"val\"])\n",
    "    train = file_list[:n_train]\n",
    "    val   = file_list[n_train:n_train+n_val]\n",
    "    test  = file_list[n_train+n_val:]\n",
    "    return {\"train\": train, \"val\": val, \"test\": test}\n",
    "\n",
    "def copy_files(files, dst_dir: Path, allow_duplicates: bool = False):\n",
    "    \"\"\"Kopieer files naar dst_dir.\n",
    "\n",
    "    - allow_duplicates=False: verwacht unieke filenames; overwrite is niet de bedoeling.\n",
    "    - allow_duplicates=True: als dezelfde file (of naam) meerdere keren wordt gebruikt, \n",
    "      maken we een unieke bestandsnaam zodat niets overschreven wordt.\n",
    "    \"\"\"\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dup_counter = defaultdict(int)\n",
    "\n",
    "    for f in files:\n",
    "        name = f.name\n",
    "        target = dst_dir / name\n",
    "\n",
    "        if allow_duplicates and target.exists():\n",
    "            # maak unieke naam: <stem>__dup0001.jpg\n",
    "            dup_counter[name] += 1\n",
    "            target = dst_dir / f\"{f.stem}__dup{dup_counter[name]:04d}{f.suffix}\"\n",
    "\n",
    "        shutil.copy2(f, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d88b5",
   "metadata": {},
   "source": [
    "## 3. Variant A â€” Imbalanced dataset\n",
    "We behouden de **originele verdeling** en maken een hold-out split per klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f13ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputmap voor imbalanced\n",
    "imbalanced_dir = OUT_ROOT / \"imbalanced\"\n",
    "\n",
    "reset_output_folder(imbalanced_dir, overwrite=OVERWRITE)\n",
    "ensure_split_dirs(imbalanced_dir)\n",
    "\n",
    "splits_imbalanced = {c: holdout_split(files_by_class[c]) for c in CLASSES}\n",
    "\n",
    "# Kopieer bestanden\n",
    "for c in CLASSES:\n",
    "    for split_name, flist in splits_imbalanced[c].items():\n",
    "        copy_files(flist, imbalanced_dir / split_name / c, allow_duplicates=False)\n",
    "\n",
    "print(\"âœ… Imbalanced dataset aangemaakt:\", imbalanced_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f5be2",
   "metadata": {},
   "source": [
    "## 4. Variant B â€” Undersampled dataset\n",
    "We maken de dataset **gebalanceerd** door per klasse exact `min_n` afbeeldingen te nemen (de grootte van de kleinste klasse), en doen daarna een hold-out split.\n",
    "\n",
    "ðŸ“Œ Voor Rubens vs Picasso betekent dit: beide klassen worden teruggebracht tot `min_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf450d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled_dir = OUT_ROOT / \"undersampled\"\n",
    "\n",
    "reset_output_folder(undersampled_dir, overwrite=OVERWRITE)\n",
    "ensure_split_dirs(undersampled_dir)\n",
    "\n",
    "# Kies per klasse exact min_n unieke afbeeldingen\n",
    "undersampled_pool = {}\n",
    "for c in CLASSES:\n",
    "    undersampled_pool[c] = random.sample(files_by_class[c], min_n)\n",
    "\n",
    "# Split de gebalanceerde set\n",
    "splits_undersampled = {c: holdout_split(undersampled_pool[c]) for c in CLASSES}\n",
    "\n",
    "# Kopieer bestanden\n",
    "for c in CLASSES:\n",
    "    for split_name, flist in splits_undersampled[c].items():\n",
    "        copy_files(flist, undersampled_dir / split_name / c, allow_duplicates=False)\n",
    "\n",
    "print(\"âœ… Undersampled dataset aangemaakt:\", undersampled_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c40ed9",
   "metadata": {},
   "source": [
    "## 5. Variant C â€” Oversampled dataset (train-set balancing)\n",
    "Bij oversampling vullen we de **kleinere klasse aan** met duplicaten zodat de **train-set** evenveel voorbeelden heeft als de grootste klasse.\n",
    "\n",
    "Waarom enkel de **train-set** oversamplen?\n",
    "- De **validatie** en **test** willen we zo 'echt' mogelijk houden (unieke originele beelden).\n",
    "- Duplicaten in test/val zouden de evaluatie vertekenen.\n",
    "\n",
    "Dus:\n",
    "- `val` en `test` = gewone hold-out uit originele data\n",
    "- `train` = oversampled tot dezelfde grootte per klasse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_dir = OUT_ROOT / \"oversampled\"\n",
    "\n",
    "reset_output_folder(oversampled_dir, overwrite=OVERWRITE)\n",
    "ensure_split_dirs(oversampled_dir)\n",
    "\n",
    "# Start van een gewone hold-out split (originele data)\n",
    "splits_base = {c: holdout_split(files_by_class[c]) for c in CLASSES}\n",
    "\n",
    "# Bepaal gewenste train-size (= max van train sizes)\n",
    "train_sizes = {c: len(splits_base[c][\"train\"]) for c in CLASSES}\n",
    "target_train_n = max(train_sizes.values())\n",
    "\n",
    "print(\"Train sizes (base):\", train_sizes)\n",
    "print(\"Target train size per klasse (oversampled):\", target_train_n)\n",
    "\n",
    "splits_oversampled = {c: {\"train\": [], \"val\": [], \"test\": []} for c in CLASSES}\n",
    "\n",
    "for c in CLASSES:\n",
    "    # val/test blijven uniek\n",
    "    splits_oversampled[c][\"val\"] = splits_base[c][\"val\"]\n",
    "    splits_oversampled[c][\"test\"] = splits_base[c][\"test\"]\n",
    "\n",
    "    base_train = splits_base[c][\"train\"]\n",
    "    if len(base_train) == target_train_n:\n",
    "        splits_oversampled[c][\"train\"] = base_train\n",
    "    else:\n",
    "        # Oversample with replacement uit de base_train set\n",
    "        # (in praktijk combineer je dit later met data augmentation om duplicaten te 'maskeren')\n",
    "        needed = target_train_n - len(base_train)\n",
    "        extra = [random.choice(base_train) for _ in range(needed)]\n",
    "        splits_oversampled[c][\"train\"] = base_train + extra\n",
    "\n",
    "# Kopieer bestanden; allow_duplicates=True voor train (anders overschrijven duplicaten)\n",
    "for c in CLASSES:\n",
    "    copy_files(splits_oversampled[c][\"train\"], oversampled_dir / \"train\" / c, allow_duplicates=True)\n",
    "    copy_files(splits_oversampled[c][\"val\"],   oversampled_dir / \"val\"   / c, allow_duplicates=False)\n",
    "    copy_files(splits_oversampled[c][\"test\"],  oversampled_dir / \"test\"  / c, allow_duplicates=False)\n",
    "\n",
    "print(\"âœ… Oversampled dataset aangemaakt:\", oversampled_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1054f58",
   "metadata": {},
   "source": [
    "## 6. Controle: aantallen per split en per klasse\n",
    "We controleren of de outputmappen de verwachte aantallen bevatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a48b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(base: Path):\n",
    "    counts = {}\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        counts[split] = {}\n",
    "        for c in CLASSES:\n",
    "            counts[split][c] = len(list((base / split / c).glob(\"*.jpg\")))\n",
    "    return counts\n",
    "\n",
    "def print_counts(title: str, base: Path):\n",
    "    c = count_images(base)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        print(f\"{split}: \", {k: v for k, v in c[split].items()})\n",
    "\n",
    "print_counts(\"IMBALANCED\", imbalanced_dir)\n",
    "print_counts(\"UNDERSAMPLED\", undersampled_dir)\n",
    "print_counts(\"OVERSAMPLED\", oversampled_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ddf2aa",
   "metadata": {},
   "source": [
    "## 7. (Optioneel) Visualiseer enkele afbeeldingen per split\n",
    "Kleine sanity check: tonen van een paar willekeurige afbeeldingen per klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def show_random_images(base: Path, split: str, class_name: str, n=3):\n",
    "    files = list((base / split / class_name).glob(\"*.jpg\"))\n",
    "    if len(files) == 0:\n",
    "        print(\"Geen files gevonden.\")\n",
    "        return\n",
    "    sample = random.sample(files, min(n, len(files)))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, f in enumerate(sample, 1):\n",
    "        img = Image.open(f)\n",
    "        plt.subplot(1, len(sample), i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f.name)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Voorbeeld: 3 willekeurige Rubens in train van undersampled variant\n",
    "show_random_images(undersampled_dir, split=\"train\", class_name=\"Rubens\", n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e9287",
   "metadata": {},
   "source": [
    "## 8. Wat hierna?\n",
    "Nu je datasets klaar staan, kan je meteen trainen met Keras:\n",
    "\n",
    "```python\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'datasets/rubens_picasso/undersampled/train',\n",
    "    image_size=(224,224),\n",
    "    batch_size=32\n",
    ")\n",
    "```\n",
    "\n",
    "Aanbevolen volgorde (zoals in het boek/les):\n",
    "1) Eenvoudige CNN baseline\n",
    "2) CNN + data augmentation\n",
    "3) VGG16 feature extraction\n",
    "4) VGG16 + augmentation\n",
    "5) Fine-tuning\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
